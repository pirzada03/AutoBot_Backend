{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kf0rAhF9N5vw"
      },
      "outputs": [],
      "source": [
        "# import sys\n",
        "# !{sys.executable} -m pip install PyPDF2\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "import io\n",
        "# import PyPDF2\n",
        "import json\n",
        "import concurrent.futures\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def new_car_by_category():\n",
        "\n",
        "    url = \"https://www.pakwheels.com/new-cars/\"\n",
        "\n",
        "    headers = {\n",
        "        'Accept': '*/*',\n",
        "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36'\n",
        "    }\n",
        "\n",
        "    response = requests.get(url, headers=headers)\n",
        "    html_source = response.text\n",
        "    soup = BeautifulSoup(html_source, 'html.parser')\n",
        "\n",
        "    alldetails = []\n",
        "    extracted_links = []\n",
        "    #Find all 'a' tags with the specified class for each make/company of cars\n",
        "    ul = soup.find_all('ul',class_='make-list col-sm-2 list-unstyled new-car-list')\n",
        "\n",
        "    for each in ul:\n",
        "      #Extract href attribute from each link\n",
        "      extracted_links.append(url + each.find('a').get('href').split('/')[2])\n",
        "\n",
        "    for link in extracted_links:\n",
        "\n",
        "      response = requests.get(link, headers=headers)\n",
        "      html_source = response.text\n",
        "      soup = BeautifulSoup(html_source, 'html.parser')\n",
        "\n",
        "      #find all new car links of each make/company\n",
        "      ul = soup.find_all('ul', class_='list-unstyled model-list row item clearfix')[0]\n",
        "      li = ul.find_all('li')\n",
        "      for each in li:\n",
        "        #Extract href attribute from each link\n",
        "        carurl = link + \"/\" + each.find('a').get('href').split('/')[3]\n",
        "\n",
        "        response = requests.get(carurl, headers=headers)\n",
        "        html_source = response.text\n",
        "        soup = BeautifulSoup(html_source, 'html.parser')\n",
        "\n",
        "        cardetails={}\n",
        "        cardetails['title'] = carurl.split('/')[4] + \" \" + carurl.split('/')[5]\n",
        "\n",
        "        #extract all data from table\n",
        "        try:\n",
        "          info_table = soup.find('table', class_='bike-version-detailscont')\n",
        "          info_rows = info_table.find_all('tr')\n",
        "          # Iterate through table rows\n",
        "          for row in info_rows:\n",
        "              columns = row.find_all('td')\n",
        "              if len(columns) == 2:\n",
        "                  label = columns[0].text.strip()\n",
        "                  value = columns[1].text.strip()\n",
        "                  cardetails[label] = value\n",
        "        except:\n",
        "          print('Table not found for ' + cardetails['title'])\n",
        "          break\n",
        "\n",
        "        print(cardetails)\n",
        "\n",
        "\n",
        "        # litags = soup.find('ul',class_='gallery light-gallery list-unstyled cS-hidden').find_all('li')\n",
        "        # images = []\n",
        "        # for li in litags:\n",
        "        #   images.append(li.get('data-src'))\n",
        "        # cardetails['images'] = images\n",
        "        alldetails.append(cardetails)\n",
        "\n",
        "     #Create a DataFrame from the car details\n",
        "    df = pd.DataFrame(alldetails)\n",
        "    # Save the DataFrame to an Excel file\n",
        "    df.to_excel('new_car_details.xlsx', index=False)\n",
        "\n",
        "    print(\"Car details saved to 'new_car_details.xlsx'\")"
      ],
      "metadata": {
        "id": "nv3bJ9gLOHXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_car_by_category()"
      ],
      "metadata": {
        "id": "KauqJf6MOiX9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}