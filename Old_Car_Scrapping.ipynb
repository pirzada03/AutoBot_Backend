{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6OwaIgUab8X",
        "outputId": "153c24b7-b83f-49d8-91cb-98a87bd0d8f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lets begin the scrapping\n"
          ]
        }
      ],
      "source": [
        "print(\"lets begin the scrapping\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def writetofile(file_path,text_content):\n",
        "    with open(file_path, 'w',encoding='utf-8') as file:\n",
        "        file.write(text_content)"
      ],
      "metadata": {
        "id": "PYUjFY9ujxRl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import sys\n",
        "# !{sys.executable} -m pip install PyPDF2\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "import io\n",
        "# import PyPDF2\n",
        "import json\n",
        "import concurrent.futures"
      ],
      "metadata": {
        "id": "fL8OUsqMjz5f"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def city_wise_scrapping(city):\n",
        "    #search_string = city.replace(\" \", \"+\")\n",
        "    counter = 0\n",
        "\n",
        "    #url = \"https://www.pakwheels.com/used-cars/search/-/ct_\" + city + \"/\"\n",
        "    url = \"https://www.pakwheels.com/used-cars/honda-n-wgn-2016-for-sale-in-lahore-8158521\"\n",
        "    headers = {\n",
        "        'Accept': '*/*',\n",
        "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36'\n",
        "    }\n",
        "\n",
        "    response = requests.get(url, headers=headers)\n",
        "\n",
        "    html_source = response.text\n",
        "    soup = BeautifulSoup(html_source, 'html.parser')\n",
        "\n",
        "    title = soup.find('div',class_='well').find('h1').text\n",
        "    location = soup.find('p',class_='detail-sub-heading').find('a').text\n",
        "    litags = soup.find('ul',class_='gallery light-gallery list-unstyled cS-hidden').find_all('li')\n",
        "    images = []\n",
        "    for li in litags:\n",
        "      images.append(li.get('data-src'))\n",
        "    modelyear = soup.find('table',class_='table table-bordered text-center table-engine-detail fs16').find_all('p')[0].text\n",
        "    millage = soup.find('table',class_='table table-bordered text-center table-engine-detail fs16').find_all('p')[1].text\n",
        "    fueltype = soup.find('table',class_='table table-bordered text-center table-engine-detail fs16').find_all('p')[2].text\n",
        "    transmission = soup.find('table',class_='table table-bordered text-center table-engine-detail fs16').find_all('p')[3].text\n",
        "    print(transmission)\n",
        "\n",
        "    # Find all 'a' tags with the specified class\n",
        "    #links = soup.find_all('a', class_='car-name ad-detail-path')\n",
        "    #Find the last page number for that city\n",
        "    #lastpage = int(soup.find('li',class_='last next').find('a').get('href').split('=')[1])\n",
        "    #print(lastpage)\n",
        "\n",
        "    # Extract href attribute from each link\n",
        "    #extracted_links = [link.get('href') for link in links]\n",
        "\n",
        "    # Print the extracted links\n",
        "    # for link in extracted_links:\n",
        "    #   carurl = \"https://www.pakwheels.com\"+link\n",
        "    #   print(carurl)\n",
        ""
      ],
      "metadata": {
        "id": "F5aauLMTa6EW"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "city = \"lahore\"\n",
        "\n",
        "# Create a ThreadPoolExecutor with 3 worker threads\n",
        "with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
        "    # Submit the tasks to run in parallel\n",
        "    futures = [executor.submit(city_wise_scrapping, city) ]\n",
        "    # futures += [executor.submit(city_wise_scrapping,\"islamabad\") ]\n",
        "\n",
        "\n",
        "    # Wait for all tasks to complete\n",
        "    concurrent.futures.wait(futures)\n",
        "print(\"All Done\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "js-5t_gpjlHr",
        "outputId": "3e99a4b0-488e-49bb-f32e-3f7231daa2aa"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Automatic\n",
            "All Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import csv\n",
        "import pandas as pd\n",
        "data= []\n",
        "for j in range(1,2):\n",
        "    url= 'https://www.pakwheels.com/used-cars/search/-/ct_islamabad/?page={}'.format(j)\n",
        "    html=requests.get(url).text\n",
        "    soup = BeautifulSoup(html, 'lxml')\n",
        "    cars= soup.find_all('div', class_=f'well search-list clearfix ad-container page-')\n",
        "    print(cars)\n",
        "    for car in cars:\n",
        "        column_names={}\n",
        "        column_names[\"Make\"]= car.find('h3', style='white-space: normal;').text.split()[0]\n",
        "        column_names[\"Model\"]= car.find('h3', style='white-space: normal;').text.split(column_names['Make'])[-1]\n",
        "        column_names[\"Model\"]= column_names['Model'].split()[0]\n",
        "        column_names[\"Year\"]= car.find('ul', class_='list-unstyled search-vehicle-info-2 fs13').text.split()[0]\n",
        "        column_names[\"Mileage\"]= car.find('ul', class_='list-unstyled search-vehicle-info-2 fs13').text.split()[1]\n",
        "        column_names[\"Engine\"]= car.find('ul', class_='list-unstyled search-vehicle-info-2 fs13').text.split()[4]\n",
        "        column_names[\"Price\"]= car.find('div', class_='price-details generic-dark-grey').text.strip()\n",
        "        if 'Call' in column_names['Price']:\n",
        "            column_names[\"Price\"]= car.find('div', class_='price-details generic-dark-grey').text.strip()\n",
        "        else:\n",
        "            column_names[\"Price\"]= car.find('div', class_='price-details generic-dark-grey').text.strip().split()[1]\n",
        "\n",
        "        print(column_names)\n",
        "        data.append(column_names)\n",
        "df = pd.DataFrame(data)\n",
        "df.to_excel(\"web_scrapping.xlsx\")\n",
        "print(\"Done!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8o9DbFzuIRX",
        "outputId": "399c96b6-1583-4908-91ab-e2a316fd8cfa"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n",
            "Done!\n"
          ]
        }
      ]
    }
  ]
}